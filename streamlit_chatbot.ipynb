{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrywVhqthrWjPWmEBLHL08",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunchae-L/LLM_chatbot/blob/main/streamlit_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOQGtxU8kQfk"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken ______"
      ],
      "metadata": {
        "id": "8r1jmiqBkUY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "\n",
        "st.title('WE ARE ☁️🐯KAIROS')\n",
        "st.write(\"Hello ☁️🐯KAIROS\")\n",
        "\n",
        "if 'name' not in st.session_state:\n",
        "    st.session_state.name = '유저이름'\n",
        "\n",
        "st.header(st.session_state.name + '님 안녕하세요')\n",
        "new_name = st.text_input(label='이름', value=st.session_state.name, placeholder='이름을 입력하세요', key='name')\n",
        "\n",
        "client = OpenAI(api_key='(본인 API KEY)')\n",
        "\n",
        "if \"openai_model\" not in st.session_state:\n",
        "    st.session_state.openai_model = \"(GPT 모델명)\"\n",
        "\n",
        "context = '''\n",
        "1. 응원곡\n",
        "고려대학교 응원단에서는 매년 고연전 오티를 기해 응원곡 신곡을 발표하고 있다.‘뱃노래’가 체계를 갖춘 최초의 응원곡으로 기록되고 있으며, 이 곡은 1974년에 발표됐다.\n",
        "1981년에 발표된 ‘엘리제’에는 당시의 디스코 문화가 반영돼 있으며, 이듬해인 1982년에 발표된 ‘석탑’에는 반정부 정서가 가미돼 있다.\n",
        " 2003년에 발표된 ‘민족의 아리아’와 2007년에 발표된 ‘들어라 보아라 그리고 기억하라’와 ‘Forever’, ‘캉캉’ 또한 많은 인기를 얻었다.\n",
        " 최근에는 밝고 경쾌한 분위기의 동작들이 가미된 응원곡들 또한 등장하고 있다.\n",
        "\n",
        "2. 입실렌티 지·야의 함성\n",
        "입실렌티 지·야의 함성은 주로 석탑대동제 마지막 날 저녁을 기해 고려대학교 응원단이 주최하는 응원제로 2011년에 34회째를 맞았다.\n",
        " 학우들의 참여 프로그램, 초청 연예인들의 공연과 응원제 프로그램으로 이루어져 있으며, 교가와 교호로 행사를 마무리한다.\n",
        " 교가와 교호로 행사를 마무리하는 방식은 입실렌티 이외의 공식적인 행사에서도 일반적이다.\n",
        "\n",
        "3. 교가와 교호:\n",
        "교가와 교호 : 현재 사용되고 있는 교가[188]는 1955년에 개교 50주년을 맞아 제정된 것이다.작사는 조지훈[196], 작곡은 윤이상이 맡았다.[197]\n",
        "교호는 1922년 구 교가(이광수 작사, 김영환 작곡)와 같은 시기에 만들어졌다.\n",
        "<교호>\n",
        "입실렌티, 체이홉\n",
        "카시코시 코시코\n",
        "칼마시 케시케시 고려대학\n",
        "칼마시 케시케시 고려대학\n",
        "\n",
        "4. 고연전\n",
        "연대는 고대로 오대빵\n",
        "'''\n",
        "\n",
        "instruction = '''\n",
        "###지시###\n",
        "장난스러운 말투로 답변해줘.\n",
        "\n",
        "###역할###\n",
        "너는 고려대학교와 관련된 질문에 답을 하는 챗봇이야.\n",
        "\n",
        "###답변형태###\n",
        "10줄이 넘어가지 않게 답변해줘. 답변의 끝에는 이모지를 붙여줘.\n",
        "'''\n",
        "\n",
        "chat_instruction = context + \"\\n\\n\" + instruction\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "    st.session_state.messages.append({\"role\": \"system\", \"content\": chat_instruction})\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    if message[\"role\"] != \"system\":\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(placeholder=\"고려대학교와 관련해 궁금한 점을 입력해주세요..\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "\n",
        "        for response in client.chat.completions.create(\n",
        "            model=st.session_state[\"openai_model\"],\n",
        "            messages=st.session_state.messages,\n",
        "            stream=True,\n",
        "            ):\n",
        "            full_response += (response.choices[0].delta.content or \"\")\n",
        "            message_placeholder.markdown(full_response + \"▌\")\n",
        "        message_placeholder.markdown(full_response)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "id": "UHm6QkSukaXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "iVFRFPLbkgZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill"
      ],
      "metadata": {
        "id": "ED-rz4OBkhbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "KYK1i_FbkiE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "qgKAhjqokiwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}