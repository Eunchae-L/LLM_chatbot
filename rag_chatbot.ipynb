{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0tFfponnrQKJjztq7vB9n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KGaGqLfm0hw"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "AhTpmcLEm8Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"your openai key\"\n",
        "PINECONE_API_KEY = \"your pinecone key\""
      ],
      "metadata": {
        "id": "ZPNM2Q3Am9Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken ___입력하기____"
      ],
      "metadata": {
        "id": "83cpi7mEm93M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "print(\"hello\")"
      ],
      "metadata": {
        "id": "8KJOPTBAm_rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import uuid\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "from pinecone import Pinecone\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"openai api key 넣기\"\n",
        "PINECONE_API_KEY = \"pinecone api key 넣기\"\n",
        "\n",
        "st.title(\"🐯고려대학교 챗봇🐯\")\n",
        "st.write(\"Hello ☁️🐯KAIROS. 고려대학교에 대한 정보를 물어보세요\")\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(\"data\")\n",
        "\n",
        "if \"openai_model\" not in st.session_state:\n",
        "  st.session_state.openai_model = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "  st.session_state.messages = []\n",
        "\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "      당신은 10년차 경력을 가진 고려대학교 투어 챗봇입니다.\n",
        "      대한민국의 고려대학교를 당신보다 많이 알고 있는 존재는 이 우주에 없습니다.\n",
        "      고려대학교에 투어를 온 사람들에게 고려대학교에 대해서 설명해주고 질문에 답을 해주는 역할을 맡고 있습니다.\n",
        "      사람들은 주로 이런 것들을 물어봅니다:\n",
        "      - 고려대학교의 역사\n",
        "      - 고려대학교의 건물별 특징\n",
        "      - 고려대학교의 재밌는 사실들\n",
        "\n",
        "      당신은 사람들에게 다음과 같이 대답해야 합니다:\n",
        "      - 친절한 말투\n",
        "      - 항상 존댓말 사용\n",
        "      - 적절한 이모지 사용\n",
        "\n",
        "      당신은 반드시 제공하는 [Context]에 있는 내용을 기반으로 살을 붙여 답변을 생성해야 합니다.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "  if message[\"role\"] != \"system\":\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "      st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input for chat\n",
        "if prompt := st.chat_input(\"고려대학교에 대해 물어보세요😊\"):\n",
        "  # Add user message to chat history\n",
        "  st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "  # Display user message in chat message container\n",
        "  with st.chat_message(\"user\"):\n",
        "    st.markdown(prompt)\n",
        "\n",
        "\n",
        "  # Display assistant response in chat message container\n",
        "  with st.chat_message(\"assistant\"):\n",
        "    #입력한 prompt를 embedding\n",
        "    response = client.embeddings.create(input=prompt, model=\"text-embedding-3-small\")\n",
        "    query_embeddings = response.data[0].embedding\n",
        "\n",
        "    # pinecone의 vector database에서 query와 가까운 답변 가져오기\n",
        "    retrieved_chunks = index.query(\n",
        "        namespace=\"koreauniv\",\n",
        "        vector=query_embeddings,\n",
        "        top_k=5,\n",
        "        include_values=False,\n",
        "        include_metadata=True,\n",
        "    )\n",
        "    contexts = \"\"\n",
        "\n",
        "    for match in retrieved_chunks.matches:\n",
        "        contexts += match[\"metadata\"][\"chunk\"] + \"\\n\\n\"\n",
        "\n",
        "    context_prompt = {\n",
        "        \"role\" : \"system\",\n",
        "        \"content\" : f\"[Context]\\n{contexts}\"\n",
        "    }\n",
        "\n",
        "    messages = [system_prompt, context_prompt]\n",
        "    messages.extend(st.session_state.messages)\n",
        "\n",
        "    message_placeholder = st.empty()\n",
        "    full_response = \"\"\n",
        "\n",
        "    for response in client.chat.completions.create(\n",
        "          model=st.session_state.openai_model,\n",
        "          messages=messages,\n",
        "          temperature=0.5,\n",
        "          max_tokens=1024,\n",
        "          stream=True\n",
        "    ):\n",
        "      full_response += (response.choices[0].delta.content or \"\")\n",
        "      message_placeholder.markdown(full_response + \"▌\")\n",
        "    message_placeholder.markdown(full_response)\n",
        "  st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "id": "kvG_kAwTnBj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&\n",
        "publ_url = ngrok.connect(addr='8501')\n",
        "publ_url"
      ],
      "metadata": {
        "id": "enM1ZwgMnC2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "zjxEZ6QBnDVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill <streamlit 번호>"
      ],
      "metadata": {
        "id": "E7YzU1lfnD8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "EhTE41YGnEqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}